<!DOCTYPE html>

<html lang='en'>
<head>
<title>Web VR Boilerplate</title>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, shrink-to-fit=no'>
<meta name='mobile-web-app-capable' content='yes'>
<meta name='apple-mobile-web-app-capable' content='yes' />
<meta name='apple-mobile-web-app-status-bar-style' content='black-translucent' />
<link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css'>
<style>
html, body {
	width: 100%;
	height: 100%;
	background-color: #004;
	color: #fff;
	margin: 0px;
	padding: 0;
	overflow: hidden;
}

canvas {
	position: fixed;
	top: 0;
}
#fullScreenContainer {
	position: fixed;
}

#buttons {
	position: fixed;
	bottom: 0;
	right: 0;
	z-index: 1;
	/*to prevent mouse selection of the button*/
	user-select: none;
	-webkit-user-select: none;
}
#buttons i {
	color: #ccc;
	font-size: 150%;
	margin-bottom: 0.4em;
	margin-right: 0.4em;
}
#buttons i:hover {
	color: #fff;
	text-shadow: 0px 0px 5px lightblue, 0px 0px 10px lightblue;
	cursor: pointer;
}
</style>
</head>

<body>
	<div id='fullScreenContainer'>
		<div id='buttons'>
			<i class='fa fa-arrows-alt' id='fullscreenButton'></i>
			<i class='fa fa-eye' id='vrButton'></i>
			<i class='fa fa-star' id='resetButton' title='reset position'></i>
		</div>
	</div>
</body>

<script>
WebVRConfig = {
	BUFFER_SCALE: 0.5,
};

document.addEventListener('touchmove', function(event) {
	event.preventDefault();
});
</script>

<!-- three.js library -->
<script src='../vendor/three.js/build/three.js'></script>

<!-- VRControls.js applies the WebVR transformations to a three.js camera object. -->
<script src='../vendor/three.js/examples/js/controls/VRControls.js'></script>

<!-- VREffect.js handles stereo camera setup and rendering.  -->
<script src='../vendor/three.js/examples/js/effects/VREffect.js'></script>
<!-- <script src='../vendor/three.js/examples/js/effects/VREffect-fromweb.js'></script> -->

<!-- A polyfill for the WebVR API.  -->
<script src='../vendor/webvr-polyfill.js'></script>

<!-- jsartookit -->
<script src="vendor/jsartoolkit/artoolkit.debug.js"></script>
<script src="vendor/jsartoolkit/artoolkit.api.js"></script>

<script>
var onRenderFcts = []

// Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
// Only enable it if you actually need to.
var renderer = new THREE.WebGLRenderer({antialias: false});
renderer.setPixelRatio(Math.floor(window.devicePixelRatio));

// Append the canvas element created by the renderer to fullScreenContainer
document.querySelector('#fullScreenContainer').appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
// var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);

// Create a camera and a marker root object for your Three.js scene.
var camera = new THREE.Camera();
camera.matrixAutoUpdate = false;
scene.add(camera);

// Apply VR headset positional data to camera.
// var controls = new THREE.VRControls(camera);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(640, 480);

// Get the VRDisplay and save it for later.
var vrDisplay = null;
navigator.getVRDisplays().then(function(displays) {
	if (displays.length > 0) {
		vrDisplay = displays[0];
	}
	
	if( vrDisplay !== null ){
		if( vrDisplay.capabilities.canPresent !== true ){
			document.querySelector('#vrButton').style.display = 'none'
		}
	}
});

// Request animation frame loop function
var lastRender = 0;
function animate(timestamp) {
	var delta = Math.min(timestamp - lastRender, 500);
	lastRender = timestamp;

	// call each function for the rendering
	onRenderFcts.forEach(function(onRenderFct){
		onRenderFct(delta)
	})
	
	// Render the scene.
	effect.render(scene, camera);
	
	// Keep looping.
	requestAnimationFrame(animate);
}

// Kick off animation loop.
requestAnimationFrame(animate);

//////////////////////////////////////////////////////////////////////////////////
//		Comments
//////////////////////////////////////////////////////////////////////////////////

function onResize() {
	console.log('no resize')
	// effect.setSize(window.innerWidth, window.innerHeight);
	// camera.aspect = window.innerWidth / window.innerHeight;
	// camera.updateProjectionMatrix();
}

// Resize the WebGL canvas when we resize and also when we change modes.
window.addEventListener('resize', onResize);
window.addEventListener('vrdisplaypresentchange', function onVRDisplayPresentChange() {
	console.log('onVRDisplayPresentChange');
	onResize();
});

// Button click handlers.
document.querySelector('#fullscreenButton').addEventListener('click', function() {
	var domElement = document.querySelector('#fullScreenContainer')
	enterFullscreen(domElement);
});
document.querySelector('#vrButton').addEventListener('click', function() {
	vrDisplay.requestPresent([{source: renderer.domElement}]);
});
document.querySelector('#resetButton').addEventListener('click', function() {
	vrDisplay.resetPose();
});

function enterFullscreen (element) {
	if (element.requestFullscreen) {
		element.requestFullscreen();
	} else if (element.mozRequestFullScreen) {
		element.mozRequestFullScreen();
	} else if (element.webkitRequestFullscreen) {
		element.webkitRequestFullscreen();
	} else if (element.msRequestFullscreen) {
		element.msRequestFullscreen();
	}
}

//////////////////////////////////////////////////////////////////////////////
//		Code Separator
//////////////////////////////////////////////////////////////////////////////


var debugEnabled = false
// var debugEnabled = true
	
var arController = null
var cameraParameters = new ARCameraParam('data/camera_para.dat', function() {
	arController = new ARController(video.width, video.height, cameraParameters);
	if( debugEnabled ){
		arController.debugSetup();
		arController.canvas.style.opacity = 0.1
	}

	var cameraMatrix = arController.getCameraMatrix();
	camera.projectionMatrix.elements.set(cameraMatrix);

	// load kanji pattern
	arController.loadMarker('Data/patt.kanji', function(markerId) {
		var markerWidth = 1
		var markerTracker = arController.trackPatternMarkerId(markerId, markerWidth);
	});
})		


//////////////////////////////////////////////////////////////////////////////
//		Code Separator
//////////////////////////////////////////////////////////////////////////////
// create the marker Root
var markerRoot = new THREE.Object3D();
markerRoot.name = 'Marker Root'
markerRoot.userData.markerMatrix = new Float64Array(12);
markerRoot.matrixAutoUpdate = false;
markerRoot.visible = false
scene.add(markerRoot);

onRenderFcts.push(function(){
	if (!arController) return;

	arController.detectMarker(video);

	if( debugEnabled )	arController.debugDraw();		

	// update markerRoot with the found markers
	var markerNum = arController.getMarkerNum();
	if (markerNum > 0) {
		// if( markerRoot.visible === false ) {
			arController.getTransMatSquare(0 /* Marker index */, 3 /* Marker width */, markerRoot.userData.markerMatrix);
		// } else {
			// arController.getTransMatSquareCont(0, 1, markerRoot.userData.markerMatrix, markerRoot.userData.markerMatrix);
		// }
		arController.transMatToGLMat(markerRoot.userData.markerMatrix, markerRoot.matrix.elements);
		

		markerRoot.updateMatrixWorld(true)
		markerRoot.matrix.decompose(markerRoot.position,markerRoot.quaternion, markerRoot.scale)
	}

	// objects visible IIF there is a marker
	if (markerNum > 0) {
		markerRoot.visible = true;
	} else {
		markerRoot.visible = false;
	}
	
})

//////////////////////////////////////////////////////////////////////////////
//	plane always in front of the camera, exactly as big as the viewpoer
//////////////////////////////////////////////////////////////////////////////

var geometry = new THREE.PlaneGeometry(2, 2);
var material = new THREE.MeshBasicMaterial({
	// map : new THREE.TextureLoader().load('images/UV_Grid_Sm.jpg'),
	side: THREE.DoubleSide,
	// opacity: 0.5,
	// transparent: true,
});
var seethruPlane = new THREE.Mesh(geometry, material);
seethruPlane.position.x = 0
seethruPlane.position.z = 17
scene.add(seethruPlane);


var video = document.createElement( 'video' );
video.loop = true;
video.volume = 0
// video.src = 'videos/headtracking.mp4';
video.src = 'videos/output_4.mp4';
video.width = 640;
video.height = 480;
video.play();


material.map = new THREE.VideoTexture( video );
material.map.minFilter = THREE.NearestFilter;
material.map.maxFilter = THREE.NearestFilter;
material.map.format = THREE.RGBFormat;
material.map.generateMipmaps = false;

onRenderFcts.push(function(delta){
// return
	camera.updateMatrixWorld(true)
	
	// get seethruPlane position
	var position = new THREE.Vector3(0,0,25)
	seethruPlane.position.copy(position)
	camera.localToWorld(seethruPlane.position)

	// get seethruPlane quaternion
	camera.matrixWorld.decompose( camera.position, camera.quaternion, camera.scale );	
	seethruPlane.quaternion.copy( camera.quaternion)

// return
	
	// get seethruPlane height relative to fov
	var fov = camera.fov
	var fov = 44
	seethruPlane.scale.y = Math.tan(THREE.Math.DEG2RAD * fov/2)*position.length()
	// seethruPlane.scale.y = 0.3880*position.length()
	// get seethruPlane aspect
	var cameraAspect = camera.aspect
	var cameraAspect = 640/480
	seethruPlane.scale.x = seethruPlane.scale.y * cameraAspect

	seethruPlane.scale.y *= -1
	
	// to mirror the video in x
	// seethruPlane.scale.x *= -1
})

window.addEventListener('resize', function(){
	updateSeeThruAspectUv(seethruPlane)	
})
video.addEventListener('canplaythrough', function(){
	updateSeeThruAspectUv(seethruPlane)
})

function updateSeeThruAspectUv(plane){
	if( video.videoWidth === 0 )	return
	if( video.videoHeight === 0 )	return
return
	var faceVertexUvs = plane.geometry.faceVertexUvs[0]
	var screenAspect = window.innerWidth / window.innerHeight
	var videoAspect = video.videoWidth / video.videoHeight
	
	plane.geometry.uvsNeedUpdate = true

	if( screenAspect >= videoAspect ){
		var actualHeight = videoAspect / screenAspect;
		// faceVertexUvs y 0
		faceVertexUvs[0][1].y = 0.5 - actualHeight/2
		faceVertexUvs[1][0].y = 0.5 - actualHeight/2
		faceVertexUvs[1][1].y = 0.5 - actualHeight/2

		// faceVertexUvs y 1
		faceVertexUvs[0][0].y = 0.5 + actualHeight/2
		faceVertexUvs[0][2].y = 0.5 + actualHeight/2
		faceVertexUvs[1][2].y = 0.5 + actualHeight/2
	}else{
		var actualWidth = screenAspect / videoAspect;

		// faceVertexUvs x 0
		faceVertexUvs[0][0].x = 0.5 - actualWidth/2
		faceVertexUvs[0][1].x = 0.5 - actualWidth/2
		faceVertexUvs[1][0].x = 0.5 - actualWidth/2
		
		// faceVertexUvs x 1
		faceVertexUvs[0][2].x = 0.5 + actualWidth/2
		faceVertexUvs[1][1].x = 0.5 + actualWidth/2
		faceVertexUvs[1][2].x = 0.5 + actualWidth/2
	}
}

//////////////////////////////////////////////////////////////////////////////////
//		add an object in the scene
//////////////////////////////////////////////////////////////////////////////////

// add a torus knot	
var geometry	= new THREE.CubeGeometry(1,1,1);
var material	= new THREE.MeshNormalMaterial({
	transparent : true,
	opacity: 0.5,
	side: THREE.DoubleSide
}); 
var mesh	= new THREE.Mesh( geometry, material );
mesh.position.z	= geometry.parameters.height/2
mesh.scale.multiplyScalar(3)
markerRoot.add( mesh );

var geometry	= new THREE.TorusKnotGeometry(0.3,0.1,32,32);
var material	= new THREE.MeshNormalMaterial(); 
var mesh	= new THREE.Mesh( geometry, material );
mesh.position.z	= 0.5
mesh.scale.multiplyScalar(3)
markerRoot.add( mesh );

onRenderFcts.push(function(){
	mesh.rotation.x += 0.1
})




</script></html>
